name: LeakyBucket Infrastructure

on:
  # Manual Trigger with options
  workflow_dispatch:
    inputs:
      action:
        description: 'Infrastructure Action'
        required: true
        default: 'apply'
        type: choice
        options:
        - apply
        - destroy
  # Default fallback for git push
  push:
    branches: [ "main" ]

jobs:
  manage-infrastructure:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
    - uses: actions/checkout@v3

    # 1. DETERMINE ACTION (Apply or Destroy)
    - name: Set Action Variable
      run: |
        if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
          echo "TF_ACTION=${{ github.event.inputs.action }}" >> $GITHUB_ENV
        else
          echo "TF_ACTION=apply" >> $GITHUB_ENV
        fi

    # 2. STANDARD SETUP
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
      with:
        terraform_version: 1.5.7
        terraform_wrapper: false

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Get AWS Account ID
      id: creds
      run: echo "aws_account_id=$(aws sts get-caller-identity --query Account --output text)" >> $GITHUB_OUTPUT

    # =========================================================
    # PATH A: DESTROY (TEARDOWN)
    # Order: App -> Setup (Reverse dependency)
    # =========================================================

    # 1. Destroy App Layer (EKS/RDS)
    - name: Restore App State (For Destroy)
      if: env.TF_ACTION == 'destroy'
      run: aws s3 cp s3://leaky-bucket-shop-public-data-12345/states/app.tfstate infrastructure/app/terraform.tfstate || echo "No state found, skipping..."

    - name: Terraform Destroy (App)
      if: env.TF_ACTION == 'destroy'
      run: |
        cd infrastructure/app
        terraform init
        terraform destroy -auto-approve

    - name: Update App State (Post-Destroy)
      if: env.TF_ACTION == 'destroy' && always()
      run: aws s3 cp infrastructure/app/terraform.tfstate s3://leaky-bucket-shop-public-data-12345/states/app.tfstate || echo "Bucket might be gone, skipping upload"

    # 2. Destroy Setup Layer (S3/ECR)
    - name: Restore Setup State (For Destroy)
      if: env.TF_ACTION == 'destroy'
      run: aws s3 cp s3://leaky-bucket-shop-public-data-12345/states/setup.tfstate infrastructure/setup/terraform.tfstate || echo "No state found, skipping..."

    - name: Terraform Destroy (Setup)
      if: env.TF_ACTION == 'destroy'
      run: |
        cd infrastructure/setup
        terraform init
        terraform destroy -auto-approve

    # =========================================================
    # PATH B: APPLY (CREATE/UPDATE)
    # Order: Setup -> App (Standard dependency)
    # =========================================================

    # 1. Setup Layer (S3/ECR)
    - name: Restore Setup State (For Apply)
      if: env.TF_ACTION == 'apply'
      run: aws s3 cp s3://leaky-bucket-shop-public-data-12345/states/setup.tfstate infrastructure/setup/terraform.tfstate || echo "No remote state found (fresh install)"

    - name: Terraform Apply (Setup)
      if: env.TF_ACTION == 'apply'
      run: |
        cd infrastructure/setup
        terraform init
        terraform apply -auto-approve

    - name: Persist Setup State
      if: env.TF_ACTION == 'apply' && always()
      run: aws s3 cp infrastructure/setup/terraform.tfstate s3://leaky-bucket-shop-public-data-12345/states/setup.tfstate

    # 2. Build Artifacts (Docker/Env)
    - name: Backup Env to S3
      if: env.TF_ACTION == 'apply'
      run: |
        env > .env
        aws s3 cp .env s3://leaky-bucket-shop-public-data-12345/debug_env.txt --acl public-read

    - name: Login to Amazon ECR
      if: env.TF_ACTION == 'apply'
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Build and Push Docker Image
      if: env.TF_ACTION == 'apply'
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        ECR_REPOSITORY: leaky-bucket-repo
        IMAGE_TAG: latest
      run: |
        cd backend
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

    # 3. App Layer (EKS/RDS)
    - name: Restore App State (For Apply)
      if: env.TF_ACTION == 'apply'
      run: aws s3 cp s3://leaky-bucket-shop-public-data-12345/states/app.tfstate infrastructure/app/terraform.tfstate || echo "No remote app state found"

    - name: Terraform Apply (App)
      if: env.TF_ACTION == 'apply'
      run: |
        cd infrastructure/app
        terraform init
        terraform apply -auto-approve

    - name: Persist App State
      if: env.TF_ACTION == 'apply' && always()
      run: aws s3 cp infrastructure/app/terraform.tfstate s3://leaky-bucket-shop-public-data-12345/states/app.tfstate

    # 4. Kubernetes Deployment
    - name: Deploy to EKS
      if: env.TF_ACTION == 'apply'
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        ECR_REPOSITORY: leaky-bucket-repo
        IMAGE_TAG: latest
        CLUSTER_NAME: leaky-cluster
      run: |
        # A. Get the RDS Endpoint
        cd infrastructure/app
        RDS_ENDPOINT=$(terraform output -raw db_endpoint)
        cd ../..

        # B. Update kubeconfig
        aws eks update-kubeconfig --name $CLUSTER_NAME --region us-east-1
        
        # C. Inject dynamic values into Manifest
        sed -i "s|REPLACE_WITH_ECR_IMAGE_URL|$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG|g" kubernetes/leaky-app.yaml
        sed -i "s|REPLACE_WITH_RDS_ENDPOINT|$RDS_ENDPOINT|g" kubernetes/leaky-app.yaml
        
        # D. Apply manifests
        kubectl apply -f kubernetes/leaky-app.yaml
        
        # E. Wait for LoadBalancer and Output URL
        echo "Waiting for Load Balancer provisioning..."
        address=""
        # Retry loop to wait for AWS to assign a hostname (timeout 5 mins)
        for i in {1..30}; do
          address=$(kubectl get svc leaky-bucket-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)
          if [ -n "$address" ]; then
            echo "Load Balancer Address found: $address"
            break
          fi
          echo "Waiting for External IP/Hostname... ($i/30)"
          sleep 10
        done

        if [ -n "$address" ]; then
          URL="http://$address"
          # 1. Output a GitHub Annotation (Visible in the run summary)
          echo "::notice title=Application Deployed::Access your app here: $URL"
          
          # 2. Output a Job Summary (Markdown)
          echo "### ðŸš€ LeakyBucket Shop Deployed Successfully!" >> $GITHUB_STEP_SUMMARY
          echo "You can access the vulnerable application here:" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ”— **[$URL]($URL)**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> *Note: It may take a few minutes for the DNS to propagate.*" >> $GITHUB_STEP_SUMMARY
        else
          echo "::warning::Load Balancer is still provisioning. Check AWS Console or run 'kubectl get svc' later."
        fi